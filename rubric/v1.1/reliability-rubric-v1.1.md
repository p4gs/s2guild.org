# **SOC 2 Reliability Rubric**

**Status**: Published

**Date**: Feb 17, 2026

**Version:** v1.1

# Overview

### What is this?

A practical framework that helps GRC and TPRM practitioners assess how much weight to give a SOC 2 report when making vendor trust decisions. The rubric provides standardized signals to identify reports that demonstrate audit rigor versus those that warrant additional scrutiny.

What this evaluates: Report reliability as evidence \- not whether a vendor's controls meet your specific needs. This rubric helps you assess the quality of the audit work itself.

### The Problem

SOC 2 reports vary widely in quality, but practitioners lack a shared way to assess that variability. Without standardized criteria, teams either treat all reports as equally credible, apply inconsistent subjective judgments, or waste time investigating every report from scratch. The result is unnecessary uncertainty for practitioners, inconsistent feedback for vendors, and an ecosystem that struggles to differentiate quality work.

### Our Approach

The rubric evaluates reports across three dimensions \- **Structure**, **Substance**, and **Source**.

* Structure failures indicate the report may not meet professional standards

* Substance failures mean the documented work doesn't support the conclusions

* Source failures suggest factors that undermine independence or credibility 

Only by evaluating all three together can practitioners determine whether a report provides reliable assurance or merely creates the appearance of compliance.

---

# Signals of SOC 2 Trustworthiness & Reliability 

Below are signals organized into three categories that practitioners can use to evaluate SOC 2 report reliability and trustworthiness. Each signal includes what to look for, why it matters, and specific steps you can take. Use these signals together; A report that passes some checks but fails others still warrants additional scrutiny or supplemental evidence requests.

| Signal | Why It Matters | What You Can Do With It |
| ----- | ----- | ----- |
| **PILLAR 1: STRUCTURE** Does the report include required components and maintain professional consistency? |  |  |
| Required Auditor’s Report section structure | AICPA standards mandate specific paragraphs be included in the report: "Scope," "Opinion," and for Type 2, "Description of Tests of Controls." are explicitly required in the Auditor’s Report section of the SOC 2\.  Missing or incorrect paragraphs indicate the auditor is unaware of the basic standard requirements of a SOC 2 audit report, or took shortcuts. | Scan the Auditor’s Report section (either Section 1 or Section 2\) for labeled paragraphs  For Type 2, verify there's a paragraph referencing tests in Section 4  Check that the Opinion clearly states whether controls were suitably designed and operating effectively. A qualified opinion will typically have an explanatory paragraph, then the opinion itself will say “Except for the matters above…” which indicates the opinion (right after that) has been qualified.   Ensure the opinions reflect the most recent format published by the AICPA. |
| Management's Assertion completeness (Section 1 or standalone) | Management must formally assert their system description is accurate, controls are suitably designed, and (Type 2\) operating effectively.  Missing or incomplete assertions mean management hasn't taken responsibility for their control environment per AICPA standards. | Find Management's Assertion in Section 1 or as a separate section. Verify it includes all required elements and is signed by company leadership. If missing, incomplete, or unsigned, the report doesn't meet basic standards ,request a complete version before proceeding with your assessment. |
| Inconsistent Language Across Report Sections (Sections 1,3,4) | Inconsistencies across report sections indicate copy-paste reuse, weak editorial control, or lack of holistic auditor review.  These discrepancies tell us that the audit firm  either did not understand and evaluate the actual environment, or did not dutifully prioritize the report user’s clarity of understanding when drafting the report. | Read the SOC2 report and take a mental note of systems across Sections 1, 3, and 4 for alignment. Common red flags include control frequencies that change between sections (eg: “quarterly” in Section 3 but “annual” testing in Section 4\) or different system names used to describe the same environment or mention of services or activities that are kept out of scope but suddenly appear in other sections (eg: org chart doesn't have a CISO and there is mention of CISO somewhere in other sections)   |
| **PILLAR 2: SUBSTANCE** Do the controls, testing, and conclusions logically align and support each other? |  |  |
| System Description specificity (Section 3\) | Section 3 should name actual products, technology stack components, infrastructure providers, and organizational structure. Generic buzzwords that could describe any company suggest the auditor didn't engage with the real environment. | Look for specific details: AWS/Azure/GCP\*, named SaaS tools, data center locations, organizational charts, architecture diagrams, subservice organizations involved in providing services, and policies and procedures.  If it reads like a marketing copy you could paste to any company, the auditor likely didn't test to the precision you would expect. Cross-reference against what you know about the vendor's actual tech stack (website details, questionnaire, subprocessor list, etc.) and other SOC 2 reports by the same auditor. Although smaller startups often have a similar tech stack, it is highly unlikely that every single item will be the exact same when comparing different companies.  Ensure that the System Description is consistent with the products or services described on the vendor’s website or marketing materials. It is certainly possible for a SOC 2 report to only cover a specific product or portion of the business. However, a System Description with a very specific boundary that seems to exclude key pieces of the environment should be scrutinized more heavily. For example, if the vendor is a healthtech SaaS tool and the Description excludes any details about third parties that process PHI, be aware that the audit may not have tested key controls related to PHI data flows outside of the environment described.\* The three dominant SaaS vendors all have Trust & Safety portals that clients with the appropriate permissions can download officially, digitally signed compliance reports from. [AWS Artifact](https://aws.amazon.com/compliance/soc-faqs/) [Azure Service Trust Portal](https://servicetrust.microsoft.com/) [Google Cloud Trust Center](https://cloud.google.com/trust-center)  |
| Control-to-criteria mapping logic (Section 4\) | Each control maps to Trust Services Criteria (like CC6.1 for logical access). Illogical mappings (like "annual meetings" mapped to technical access controls) suggest the auditor didn't think critically about what controls actually accomplish. | Spot-check 10 control mappings. Ask: does this control logically address this criterion? If technical controls are mapped to wrong categories or soft controls are used for hard technical requirements, the scoping wasn't thoughtful. For example, document questionable mappings and probe whether those areas are well-designed. Poor mapping can potentially mask control gaps and fail to ensure that the audit properly tested an important control.  |
| Vague or conflicting control descriptions (Sections 3 and 4\)  | Vague controls like "Management maintains security" don't tell you what's actually happening. Clear controls specify what happens, who does it, how often, and what makes it effective. Poorly designed controls may miss one or some of these elements.  Also important are controls that do not contradict or describe incompatible processes. When two controls governing the same risk cannot both be operating as written, at least one of them is ineffective or inaccurately described. | Read control descriptions for specificity. A well designed control should answer 5 questions: What is done? / How is it done? / Who does it? / When it is done? / Where is it done? **Good:** "Security team reviews production access quarterly, validates business justification with managers, removes unjustified access within 24 hours."  **Bad**: "Access is reviewed periodically." If controls are consistently vague, you can't assess their relevance \- request the vendor's actual control documentation. Review controls side by side in Section 3 and trace testing to Section 4\.  Look out for controls requiring approvals that other controls explicitly bypass, overlapping controls with different populations (e.g. “all users” vs “excluding service accounts” vs “no contractors”), or controls that imply different sources of truth for the same activity.  For example, you might see a note that developers have no access to production data in one place, but a sentence indicating that there is limited production data access in another.  |
| Test procedure detail and specificity (Section 4\) | Vague test descriptions like "reviewed evidence" or “inspected evidence” are unhelpful. Look for testing descriptions that indicate the test itself was reperformed or observed.  Also ensure that sample sizes for testing are large enough to provide stronger confidence. Small sample sizes may not accurately portray control effectiveness.  An unqualified report despite extensive exceptions and non-occurring controls discovered during testing can indicate the audit firm’s conflict avoidance or pressure to preserve the client relationship impacting their professional judgment. | Pick 5-7 controls critical to your use case and read their test procedures line by line. Look for: what evidence was examined, how many samples, from what time periods, what specifically was verified. If procedures are interchangeable boilerplate that could apply at any company, flag these controls and request direct evidence from the vendor. For example, if there was a test that involved an auditor reviewing a screenshot of users, look for signs of details that were reviewed such as roles, usernames, last login times, etc.  For your critical controls, count the samples and check timing. Samples should be selected from multiple dates during the monitoring period to ensure continuous assurance. For technical controls (MFA, encryption), look for testing of configuration and system-generated evidence. For periodic controls (quarterly reviews), verify all instances were tested. Small samples (5-10) or period-end clustering is a limitation \- note it and consider direct verification. Count exceptions across Section 4 and assess whether exceptions are pervasive and/or impact core security objectives. Challenge whether the opinion appropriately reflects the severity of the exceptions noted.  Review non-occurring controls, and scrutinize illogical or uncommon scenarios. Make sure that the audit firm has disclosed that they performed a meaningful validation to justify the non-occurrence. |
| **PILLAR 3: SOURCE** What credentials, independence factors, and track record may affect report credibility? |  |  |
| Appropriate registration CPA firm registration Firm Peer Review enrollment status Firm AICPA Peer Review Results | The audit firm must be registered as a CPA firm with its respective State Board to operate as a licensed firm. The audit firm must be enrolled in the AICPA Peer Review Program and be subject to peer reviews every three years. The audit firm must pass peer review every three years to ensure they have a proper system of quality management in place for performing SOC 2 audits.  These are all indicators the audit may not be subject to proper oversight, and the final report issued by a CPA firm may not be meeting AICPA quality standards. | Look at the bottom of Section 1 or Section 2 for the firm name, firm signature, and the home state of the CPA firm. Verify registration of the firm at NASBA’s [CPAVerify tool](https://ald.nasba.org/search/cpa). This is the official nation-wide firm lookup service, populated by publicly available, official state regulatory data sent from state level Boards of Accountancy to the Accountancy Licensee Database (ALD)  If you can't confirm the CPA firm is a licensed CPA firm in the state listed in the report, reject the report and communicate to the vendor that you can’t accept a SOC 2 report from a CPA firm that isn’t licensed by a state in the U.S. Note: Firm license data is not currently sent to NASBA for the following jurisdictions: North Dakota, Nebraska, New York, Pennsylvania,, West Virginia, and Wyoming. If the firm is registered in one of these states, you will need to search directly in the public database for these states’ Board of Accountancy: [North Dakota](https://ndsba.certemy.com/public-registry/cb166e46-8bb1-44ea-acc3-8ef342c9a845) [Nebraska](https://nbpa.certemy.com/public-registry/4c8599b3-bab3-4b24-bd62-0dc83232cb10) [New York](https://eservices.nysed.gov/professions/verification-search) [Pennsylvania](https://www.pals.pa.gov/#!/page/search) [West Virginia](https://www.boa.wv.gov/verifications/index.asp) [Wyoming](https://online.wycpaboard.org/#/VerifyLicense)  Perform a public file search to validate AICPA Peer Review registration at [aicpa.org](https://peerreview.aicpa.org). If the firm does not show up in search results, then they are not enrolled in the AICPA Peer Review Program. Reject the report. If the firm is enrolled in the AICPA Peer Review Program, the search results will show the “Report Rating”. Ensure the “Report Rating” is “Pass”. Also confirm the Peer Review acceptance date not older than three years.  Note: CPA firms do not need to complete their first peer review until 18 months after they issue their first attestation report. If the firm is enrolled in the AICPA Peer Review Program, but has no results for Peer Review, follow up with the vendor to ensure the CPA firm is still within the 18-month window. If they are outside the 18-month window, then this could be a signal that they are having issues with completing a peer review. Obtain assurance from the CPA firm about when their peer review will be completed.  |
| CPA to SOC reports issued ratio | Auditing standards require a licensed CPA to sign off on every SOC report. A  high ratio (too many reports per CPA) suggests that the firm may be operating as a "signature mill" without prioritizing quality. | Look up the CPA firm on LinkedIn and confirm how many licensed CPAs work for the CPA firm. Research the firm to determine if you can come up with an estimate of the number of SOC reports they issue a year. If you believe the ratio of licensed CPAs to SOC reports issued per year is greater than 50:1, then this could be a signal that quality is not prioritized. Factor this into your assessment and ask for more supplemental evidence. |
| CPA firm leadership and report signer experience with SOC 2 | CPA leadership determines whether a firm operates as an independent guardian of security or a high-volume "audit mill," as their oversight dictates whether staff apply rigorous professional skepticism or simply follow automated checklists. Ultimately, the quality of a report rests on a leader’s willingness to prioritize their professional license and technical accuracy over the easy profits of a "rubber-stamp" commercial partnership. | Research the firm’s founders, the managing partner, and the CPAs signing reports on LinkedIn to determine if they have sufficient experience in performing SOC 2 audits. If they do not have sufficient experience, this may indicate that leadership does not understand the AICPA’s quality and independence standards required to perform a quality SOC 2 audit. Factor this into your assessment and ask for more supplemental evidence.  |
| Use of a GRC Tool | Some GRC tools market "instant" SOC 2 compliance, promising their customers will complete SOC 2 audits in hours or days and even guaranteeing a "pass". Such marketing often signals a "commodity audit" that prioritizes speed over substance. A vendor using these GRC tools to obtain a SOC 2 report can be a red flag for low quality. | TPRM teams can quickly identify a vendor's GRC tool by examining the vendor's Trust Center. In many instances, the vendor is using the GRC tool's Trust Center product as well. If the vendor does not have a Trust Center, you will have to inquire with the vendor to determine which GRC tool they used. Once the tool is identified, research its website for marketing claim: Look for slogans promising "SOC 2 in days, hours, or weeks." If the tool prioritizes speed, the vendor may have rushed through critical risk assessments. Look for terms like "Audit-Ready Guarantee" or "100% Success Rate." This often signals a "check-the-box" culture where the auditor acts as a rubber stamp for the GRC tool. See if the tool has a list of "preferred auditors." If your vendor's auditor is on that list, their independence may be weakened by a high-volume, automated business model. Factor this into your assessment and ask for more supplemental evidence.  |
| Customer feedback | Reviewing verified customer feedback about vendors involved in conducting and producing audits can provide useful signals for determining source trustworthiness – or lack thereof. Likewise, providing your own honest customer feedback, and encouraging peers to do the same, helps ensure that customer feedback sites consist of recent, relevant, and reliable signals about audit sources' trustworthiness. | Review and provide feedback about SOC 2 vendors' work quality on [Gartner Peer Insights](https://www.gartner.com/peer-insights/home) and/or [G2](https://www.g2.com). When you encounter SOC 2 reports from sources with concerning reviews, communicate this to the service organization you're assessing, encouraging them, or contractually obligating them, to work with a more trustworthy SOC 2 vendor for their next audit cycle. Consider ignoring SOC 2 reports from untrustworthy sources and require your service organizations to provide direct evidence of control operating effectiveness instead, which can create an incentive for them to use a better SOC 2 vendor in the future. |

# ---

# Tactical Responses

So you’ve got a low quality report on your hands. Now what? 

**Focus on Education, Not Accusations**: Any response with the vendor should be approached with curiosity and clarity, not blame. Many well-meaning vendors, operating strong security programs, may not understand what a high-quality SOC 2 report means or were guided into a low-rigor audit by cost or sales pressure. Take this as an opportunity to enhance the relationship and grow their understanding.

**Communicate with the Vendor:** Don’t silently downgrade trust. If material concerns are identified, explain what you’re seeing and why it matters. Clear, specific feedback helps vendors improve and strengthens trust across the ecosystem. By showing them why it matters and how it works, we can tell them "this year we can do a manual review since your 2025 report was not of acceptable quality, we'll need to see XYZ changes in the 2026 report to accept it"

**Involve Stakeholders Early:** Business owners, risk owners, and technical stakeholders need to be involved from the start. These teams are most impacted by delayed approvals, compensating controls, and risk acceptance and often have critical context that informs the final decision.

**Apply a Risk-Based Lens:** Not all vendors carry the same risk. Consider data sensitivity, access level, deployment model, and business criticality. A low-impact vendor may warrant lighter scrutiny than a mission-critical system.

**Identify Practical Mitigations:** If the report isn’t sufficient, consider alternatives before rejection. Request supplemental evidence for key controls, limit production access or scope of deployment, or delay rollout until improvements are made. Even partial approval or constrained adoption can be meaningful to the vendor and create strong incentives to improve audit quality in future cycles**.** This approach can also reaffirm a GRC team being a business enabler that makes risk based decisions rather than the Team of No. 

**Use Commercial and Contractual Levers:** When a SOC 2 report cannot be reasonably relied upon, additional assurance work may be necessary. The cost of supplemental reviews, evidence requests, or ongoing monitoring can be addressed through contract terms, negotiations, or security addenda. This may include requiring a higher-quality auditor in future cycles, mandating specific controls or audit procedures, or pricing in the additional cost of oversight.Your Annual Contract Value (ACV) and total contract value (TCV) as a client will have a significant impact on your ability to negotiate favorable terms to mitigate or transfer risk in alignment with your tolerances. GRC teams going this route should proactively manage expectations and align as early as possible with internal stakeholders.

**Be Willing to Interact with the Auditor:** The audit community gets very little feedback from report consumers. Constructive engagement and specific concerns can improve future audits, not just for one vendor but for the broader ecosystem.

**Document the Evaluation:** Ultimately, this is a risk based exercise. Whether risk is mitigated, transferred, or accepted, document the rationale to support your own governance obligations and business needs.

# License

Copyright © 2026 SOC 2 Quality Guild. This work is licensed under Creative Commons Attribution-ShareAlike 4.0 International ([CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/)).
